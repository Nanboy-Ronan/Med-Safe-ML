# Med-Safe-ML
Welcome to Med-Safe-ML, a collection of academic articles, published methodology and datasets on trustworthy machine learning in healthcare and medicine.

## Topics

### Explanable Machine Learning
| **Paper Title** | **Year** | **Venue** | **Code** | **Summary** |
| --------------- | :----: | :----: | :----: | ---- |

### Federated Learning
| **Paper Title** | **Year** | **Venue** | **Code** | **Summary** |
| --------------- | :----: | :----: | :----: | ---- |

### Attacks and Defenses
| **Paper Title** | **Year** | **Venue** | **Code** | **Summary** |
| --------------- | :----: | :----: | :----: | ---- |
| Shared Adversarial Unlearning: Backdoor Mitigation
by Unlearning Shared Adversarial Examples | 2023 | NeurIPS | [SAU](https://github.com/SCLBD/BackdoorBench) | The paper proposed Shared Adversarial Unlearning (SAU), which it first generates shared adversarial examples (SAEs), and then, unlearns the generated SAEs such that they are either correctly classfied by the purified model and/or differently classified by the two models. |
| --------------- | :----: | :----: | :----: | ---- |